# Online Learning
---
- In **online learning**, the model is trained on the dataset incrementally, i.e, the model is trained sequentially on small mini batches of the dataset
- Since the mini-batches are quite small, they can be used to train the model directly on the server
- Since the model runs on the server, the model can utilise any new data received by the server on the fly without having to re-train from scratch
- The model in online learning, simultaneously predicts and learns
- Example: YouTube recommendations, Keyboard suggestions, etc...
- Online Learning is suitable when the data or the problem to be solved is continuously changing. It is a cost effective and faster solution
- Some useful libraries for online learning: [river](https://github.com/online-ml/river), [vowpal wabbit](https://github.com/VowpalWabbit/vowpal_wabbit)
- [[42.02 Learning Rate|Learning rate]] is an important factor that affects the performance, stability and accuracy of models trained through online learning
- Online learning can be used in scenarios (locally) where batch learning is physically impossible due to memory constraints (the data maybe so large that it cannot be loaded into memory at a single go)
- Disadvantages:
	1. Factors such as learning rate and batch size can influence the predictions to such an extent that the process of making reliable predications becomes tricky
	2. This kind of learning is quite risky as the model is vulnerable to sudden changes in data that was a result of some malfunction or malicious activity