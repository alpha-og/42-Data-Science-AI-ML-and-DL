# Regularisation
---
- Regularisation involves the prevention of [[42.02 Introduction#^1e2789|overfitting]] by:
	- Stopping the model training prior to convergence of loss (OR)
	- Penalising the model complexity
- While stopping the model training prior to convergence of loss can be helpful it is not quite simple to implement as its a bit of beating around the bush before you get any tangible results. Thus we instead more commonly resort to penalising the model complexity
## Penalising the Model Complexity
- Just as [[42.02 Generalisation#^180d5e|Ockham's Razor]] suggests, it is advisable to minimise the complexity of the model
- In order to keep a check on the model complexity we introduce a new term, **Structural Risk Minimisation** which aims to minimise loss while at the same time balancing against complexity of the model
- One of the strategies used is to *prefer smaller weights*
- Methods:
	1. $\ce{L_2}$ Regularisation (Ridge Regularisation)
### Ridge Regularisation
- Also known as $\ce{L_2}$ Regularisation
- This method tries to ensure that the weights aren't larger than they need to be 
- Fundamental idea: $$minimize(Loss(Data|Model) + \lambda (complexity(Model)))$$
- Bayesian prior for the situation:
	1. weights should be centred around zero
	2. weights should be normally distributed
- The complexity of the model for this method is given by the sum of squares of the weights

> [!tip] Why do we consider the weights to measure model complexity?
> - Large values of weights cause certain inputs to influence the output more than others. When this influence is much greater than what is reasonably expected, the model complexity may be very high and could potentially lead to overfitting
> - Read this [article](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization) on ridge regularisation and take a look at the example at the end of the article to understand why regularisation is important

- Loss function with $\ce{L_2}$ regularisation $$Loss(Data|Model) + \lambda \left(w_1^2 + \ldots + w_n^2 \right)$$
- The first term of the aforementioned loss function is the training loss which is dependent on the training data
- The second term which is the $\ce{L2}$ Regularisation term (model complexity) is independent of the training data
- $\lambda$ is a co-efficient that defines the proportion or extent to which less complexity matters against getting correct predictions (or factor which controls the influence of regularisation on the model)
	- Value of $\lambda$ is context dependent and will have to be changed in various scenarios
	- If the training and test data are similar then you would want less regularisation (leading to a complex model) to prevent [[42.02 Introduction#^3d1d7f|underfitting]] and hence a smaller value of $\lambda$
	- If the training and test data were significantly different from each other then you would want a great deal of regularisation (a simple model) to prevent overfitting and hence a larger value of $\lambda$

> [!important] Benefits of Ridge Regularisation 
> 1. Encourages weight values toward 0 (but not exactly 0)
> 2. Encourages the mean of the weights toward 0, with a normal (bell-shaped or Gaussian) distribution.

