# Feature Engineering
---
- Feature engineering involves the following aspects:
	1. Feature Transformation
	2. Feature Construction
	3. Feature Selection
	4. Feature Extraction
## Feature Transformation
- Feature transformation involves the transformation or change of available data to a form that would prove to be much more apt for the ML algorithm
- Feature Transformation comprises the following processes (not in any particular order):
	- [[42.02 Handling Missing Values|Handling Missing Value]]
	- [[42.02 Feature Encoding|Feature Encoding]]
	- [[42.02 Outliers|Handling Outliers]]
	- [[42.02 Feature Scaling|Feature Scaling]]
	- [[42.02 Handling Some Specific Types of Data|Handling Some Specific Types of Data]]
## Feature Construction
- Reference video: https://youtu.be/ma-h30PoFms
- Feature construction involves creation of new features using already available features
- An example of this is [[42.02 Feature Crosses|feature cross]]
- The process of feature construction is an intuition driven process which is akin to an art since there is no definitive method to follow
- Example:
	- In the titanic dataset, there are two features in particular that are related and can be used to create a new feature, namely "Parch" and "SibSp" 
	- The two columns can be combined to create a new column called "FamilySize" (this is exclusive of the passenger themself)
	- Now with the new feature introduced, we may discard the "Parch" and "SibSp" features â€” known as Dimensionality Reduction
## Feature Splitting
- Feature splitting involves creation of new features by splitting already available features
- This technique can be applied on features whose values have multiple different values combined into a single entry. For example, the name feature may have values such as "Mr. Arun" where "Mr." is a salutation while "Arun" is the name; so we may split the name column into two
## Feature Selection
- Feature selection is the process of selecting or plucking out useful features from a large array of features
- Feature selection can greatly speed up the time taken to train models
- However, it is important to note that picking the right features is necessary to produce desirable outcomes
- Techniques:
	1. Forward Selection
	2. Backward Elimination
	3. Bi-directional Elimination
## Feature Extraction
- Feature extraction helps in reducing the number of features by introducing a new feature altogether that covers the purpose of those features it replaces
- Some algorithms used in this process are: 
	1. Principle Component Analysis
	2. Linear Discriminant Analysis
	3. TSME