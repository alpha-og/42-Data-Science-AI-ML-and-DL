# Feature Engineering
---
- Feature engineering involves the following aspects:
	1. Feature Transformation
	2. Feature Construction
	3. Feature Selection
	4. Feature Extraction
## Feature Transformation
- Feature transformation involves the transformation or change of available data to a form that would prove to be much more apt for the ML algorithm
- Feature Transformation comprises the following processes (not in any particular order):
	- Handling Missing Value
	- [[42.02 Feature Encoding|Feature Encoding]]
	- outlier detection
	- [[42.02 Feature Scaling|Feature Scaling]]
	- [[42.02 Handling Some Specific Types of Data|Handling Some Specific Types of Data]]
[[42.02 Handling Missing Values]]

### Outlier Detection
- Outliers are those values which are extremely different from the rest of the dataset and their removal leads to greater [[42.02 Generalisation|generalisation]] of the model ^01b500
- Removal of outliers is a rather simple process, however their detection can be difficult as often times we are unaware of which data points may act as outliers unless we analyse the data
## Feature Construction
- Feature construction involves creation of new features using already available features
- An example of this is [[42.02 Feature Crosses|feature cross]]
- The process of feature construction is an intuition driven process which is akin to an art since there is no definitive method to follow
## Feature Selection
- Feature selection is the process of selecting or plucking out useful features from a large array of features
- Feature selection can greatly speed up the time taken to train models
- However, it is important to note that picking the right features is necessary to produce desirable outcomes
## Feature Extraction
- Feature extraction helps in reducing the number of features by introducing a new feature altogether that covers the purpose of those features it replaces
- Some algorithms used in this process are: PCA, LDA, TSME