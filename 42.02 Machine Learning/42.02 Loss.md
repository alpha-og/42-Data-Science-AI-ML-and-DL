# Loss
---
- It can be seen as a penalty for bad prediction and minimising this loss is crucial
- A model capable of making perfect predictions will have *zero* loss as opposed to a greater value of loss in all other cases
- The higher the loss, the less accurate/ precise a model is in making predictions
- The following factors have influence on loss:
	- features/ inputs
	- hyperparameters (weights, biases, etc...)
- When attempting to minimise loss, it is advisable to adjust the hyperparameters instead of the features since the features, in the real world, are beyond our control (apart from the quality and accuracy of the feature data)
## Reducing Loss 
- A high loss value is undesirable as it is indicative of a poor model
- In order to decrease the loss a variety of approaches can be considered such as:
	1. Gradient Descent
	2. Adjusting the initialisation values of hyperparameters (in the case of non-convex problems)
	3. Altering the number of neurons and layers in a neural network
	4. Cleaning the input data to have fewer or no redundant features 
### Gradient Descent
- In order to reduce loss, it is important to establish a relationship between the inputs, hyperparameters and the loss
- To determine the relationship, we can determine the gradient of the loss with respect to each hyperparameter to identify how change in the value of one or more of these hyperparameters influences the loss value
- The negative of the gradient tells us what kind of value is to be added to the hyperparameter so as to decrease loss
- In gradient descent, the product of negative of gradient of the loss function, with respect to each hyperparameter, with the [[42.02 Learning Rate|learning rate]] is added to the corresponding hyperparameter over a series of iterations which eventually leads to a lower loss ^c77ace
- This is based on the simple concept of increasing and decreasing functions
- **Case 1: Positive Gradient**
	- Consider that the derivative (gradient) of the loss function with respect to a certain hyperparameter is positive
	- In such a case, the loss function is increasing with respect to that hyperparameter
	- Thus higher values of the hyperparameter increases the value of loss function while lower values of the hyperparameter decreases the value of loss function
	- Therefore we need to add [[#^c77ace|some value]] to the hyperparameter so as to decrease the value of the hyperparameter and subsequently decrease the loss
- **Case 2: Negative Gradient**
	- Consider that the derivative (gradient) of the loss function with respect to a certain. hyperparameter is negative
	- In such a case, the loss function is decreasing with respect to that hyperparameter
	- Thus higher values of the hyperparameter decreases the value of loss function while lower values of the hyperparameter increases the value of loss function
	- Therefore we need to add [[#^c77ace|some value]] to the hyperparameter so as to increase the value of the hyperparameter and subsequently decrease the loss
- Mathematically it may seem necessary to calculate the gradients over the entire dataset at each step, however in practise this is unnecessary and in case of large datasets it would be very taxing to calculate
	- We can instead calculate gradient on a single random sample at a time (batch size of 1 example) — known as **Stochastic Gradient Descent** or **SGD** ^c026b0
	- Another approach is to calculate the gradient over small batches (batch size of 10-1000 random examples) wherein the loss and gradients are averaged over the batch — known as **Mini-Batch Stochastic Gradient Descent** or **Mini-Batch SGD**