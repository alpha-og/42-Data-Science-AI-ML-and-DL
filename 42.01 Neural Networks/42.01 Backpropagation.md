# Backpropagation
---
- The technical term for obtaining the gradient is termed as backpropagation
- *Backpropagation* involves the determination of the change in the output as a result of change in any of the variables that constitute the function whose output is obtained â€” we take derivative of the output with respect to the preceding variables and apply chain rule to get the gradient with respect to each node (doesn't feel too intuitive but try it in code/ flowchart to see what I mean)